{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b940985",
      "metadata": {
        "id": "0b940985"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as opt\n",
        "import os\n",
        "from PIL import Image\n",
        "from typing import Tuple\n",
        "from tqdm.auto import tqdm, trange\n",
        "import torchvision.transforms.functional as f\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e8f9971",
      "metadata": {
        "id": "7e8f9971"
      },
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b858e811",
      "metadata": {
        "id": "b858e811"
      },
      "source": [
        "train: 10000  \n",
        "valid: 200  \n",
        "test: 420"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f3a3846",
      "metadata": {
        "id": "1f3a3846"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"data/train-small.csv\")\n",
        "valid_df = pd.read_csv(\"data/valid-small.csv\")\n",
        "test_df = pd.read_csv(\"data/test.csv\")\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "365eda80",
      "metadata": {
        "id": "365eda80"
      },
      "source": [
        "Kiểm tra rò rỉ dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a58bf780",
      "metadata": {
        "id": "a58bf780"
      },
      "outputs": [],
      "source": [
        "def check_leakage(df1, df2, column):\n",
        "    \"\"\"\n",
        "    Kiểm tra rò rỉ dữ liệu giữa hai DataFrame dựa trên một cột.\n",
        "    Trả về True nếu không có giá trị trùng lặp, False nếu có rò rỉ.\n",
        "    \"\"\"\n",
        "    overlap = set(df1[column]).intersection(set(df2[column]))\n",
        "    if len(overlap) == 0:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "336f07ca",
      "metadata": {
        "id": "336f07ca"
      },
      "outputs": [],
      "source": [
        "print(f\"Check_leakage train - test : {check_leakage(train_df,test_df,'PatientId')}\")\n",
        "print(f\"Check_leakage valid - test : {check_leakage(valid_df,test_df,'PatientId')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8cf232a",
      "metadata": {
        "id": "f8cf232a"
      },
      "outputs": [],
      "source": [
        "print(f\"Check_leakage train - valid : {check_leakage(train_df,valid_df,'PatientId')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26a95424",
      "metadata": {
        "id": "26a95424"
      },
      "outputs": [],
      "source": [
        "overlap = set(train_df['PatientId']).intersection(set(valid_df['PatientId']))\n",
        "train_df = train_df[~train_df['PatientId'].isin(overlap)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21a2ba3a",
      "metadata": {
        "id": "21a2ba3a"
      },
      "outputs": [],
      "source": [
        "print(f\"Check_leakage train - valid : {check_leakage(train_df,valid_df,'PatientId')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dd5fd2b",
      "metadata": {
        "id": "3dd5fd2b"
      },
      "outputs": [],
      "source": [
        "labels = ['Cardiomegaly',\n",
        "          'Emphysema',\n",
        "          'Effusion',\n",
        "          'Hernia',\n",
        "          'Infiltration',\n",
        "          'Mass',\n",
        "          'Nodule',\n",
        "          'Atelectasis',\n",
        "          'Pneumothorax',\n",
        "          'Pleural_Thickening',\n",
        "          'Pneumonia',\n",
        "          'Fibrosis',\n",
        "          'Edema',\n",
        "          'Consolidation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc5e8d53",
      "metadata": {
        "id": "cc5e8d53"
      },
      "outputs": [],
      "source": [
        "class ChestXrayDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, labels, transform=None):\n",
        "        self.df = df\n",
        "        self.image_dir = image_dir\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load ảnh\n",
        "        image_path = f\"{self.image_dir}/{self.df.iloc[idx]['Image']}\"\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        # Lấy nhãn tương ứng, dạng vector 0/1 theo thứ tự trong labels\n",
        "        label_vector = torch.tensor(\n",
        "            self.df.iloc[idx][self.labels].values.astype('float32')\n",
        "        )\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4c6aac9",
      "metadata": {
        "id": "d4c6aac9"
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = ChestXrayDataset(train_df, './data/images_small',labels, transform_train)\n",
        "valid_dataset = ChestXrayDataset(valid_df, './data/images_small',labels, transform)\n",
        "test_dataset =  ChestXrayDataset(test_df, './data/images_small',labels, transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ab76f14",
      "metadata": {
        "id": "3ab76f14"
      },
      "outputs": [],
      "source": [
        "# Lấy ảnh và nhãn đầu tiên từ dataset\n",
        "image, label = test_dataset[5]\n",
        "\n",
        "# chuyển sang numpy và đưa về [H,W,C]\n",
        "if isinstance(image, torch.Tensor):\n",
        "    image = f.to_pil_image(image)\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "print(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c4113e7",
      "metadata": {
        "id": "2c4113e7"
      },
      "outputs": [],
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4  # output_channels = out_channels * 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion,\n",
        "                               kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet50(nn.Module):\n",
        "    def __init__(self, num_classes=14):  # 14 diseases\n",
        "        super(ResNet50, self).__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(Bottleneck, 64, blocks=3)\n",
        "        self.layer2 = self._make_layer(Bottleneck, 128, blocks=4, stride=2)\n",
        "        self.layer3 = self._make_layer(Bottleneck, 256, blocks=6, stride=2)\n",
        "        self.layer4 = self._make_layer(Bottleneck, 512, blocks=3, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * Bottleneck.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9958085",
      "metadata": {
        "id": "b9958085"
      },
      "outputs": [],
      "source": [
        "def evaluate(net: nn.Module, data, threshold=0.5) -> float:\n",
        "    data_loader = torch.utils.data.DataLoader(data,\n",
        "                                              batch_size=100,\n",
        "                                              shuffle=False)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    net.to(device)\n",
        "    net.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device).float()\n",
        "\n",
        "            outputs = net(inputs)\n",
        "            probs = torch.sigmoid(outputs)\n",
        "            preds = (probs > threshold).float()\n",
        "            correct += (preds == targets).all(dim=1).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a2b223f",
      "metadata": {
        "id": "2a2b223f"
      },
      "outputs": [],
      "source": [
        "def train(train_data,\n",
        "          val_data,\n",
        "          net,\n",
        "          **kwargs) -> Tuple[nn.Module, list[float], list[float], list[float]]:\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    net.to(device)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=kwargs['batch_size'], shuffle=True)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=kwargs['batch_size'], shuffle=False)\n",
        "\n",
        "    optimizer = opt.Adam(net.parameters(), lr=kwargs['lr'], weight_decay=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=kwargs['epochs'])\n",
        "    criterion = nn.BCEWithLogitsLoss()  # Multi-label loss\n",
        "\n",
        "    pbar = trange(kwargs['epochs'])\n",
        "    for epoch in pbar:\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, targets in tqdm(train_loader, leave=False):\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device).float()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Đánh giá train\n",
        "        train_accuracy = evaluate(net, train_data)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Đánh giá validation\n",
        "        net.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in val_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                targets = targets.to(device).float()\n",
        "                outputs = net(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_accuracy = evaluate(net, val_data)\n",
        "        test_accuracy = evaluate(net,test_dataset)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        pbar.set_description(\n",
        "            f\"Epoch {epoch+1} | TrainLoss: {running_loss/len(train_loader):.4f} | \"\n",
        "            f\"TrainAcc: {train_accuracy:.4f} | ValLoss: {val_loss:.4f} | ValAcc: {val_accuracy:.4f} | TestAcc:{test_accuracy:.4f}\"\n",
        "        )\n",
        "\n",
        "    return net, train_losses, train_accuracies, val_losses, val_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6f28bc4",
      "metadata": {
        "id": "a6f28bc4"
      },
      "outputs": [],
      "source": [
        "net = ResNet50()\n",
        "lr = 0.05\n",
        "batch_size = 32\n",
        "epochs = 70\n",
        "net, train_losses, train_accuracies = train(train_data=train_dataset,\n",
        "                                            val_data=valid_dataset,\n",
        "                                            net=net,\n",
        "                                            lr=lr,\n",
        "                                            optimizer='adam',\n",
        "                                            batch_size=batch_size,\n",
        "                                            epochs=epochs)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}